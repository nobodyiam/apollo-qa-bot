server:
  port: 9090

management:
  endpoints:
    web:
      base-path: /

logging:
  file:
    name: /opt/logs/qa-bot.log

cors:
  # the allowed origins for the site that can access the QA bot
  allowedOrigins:
    - '*'

assistant:
  # the model for the assistant
  model: gpt-4o-mini
  # the assistant name
  name: apollo-qa-bot
  # the instructions used to generate the answer
  instructions: |
    You are an AI assistant for answering questions for apollo, which is a very popular configuration management system suitable for microservice configuration management scenarios.
    You are given the following extracted parts of a long document and a question. Provide a conversational answer.
    You need to first determine what language the question is in, and then give the answer in the same language.
    If you don't know the answer, just say "Hmm, I'm not sure." Don't try to make up an answer.
    Only output the answer to the question, with nothing else.
  # the vector store id
  vector-store-id: xxxxxxxxxx

markdown:
  files:
    # the markdown files location, e.g. for apollo, it's the folder of https://github.com/apolloconfig/apollo/tree/master/docs
    location: xxxxxxxxxx
    # the markdown files roots in the documentation site, e.g. for apollo, it's /zh and /en
    # https://github.com/apolloconfig/apollo/blob/master/docs/zh/design/apollo-design.md => https://www.apolloconfig.com/#/zh/design/apollo-design
    # https://github.com/apolloconfig/apollo/blob/master/docs/en/design/apollo-design.md => https://www.apolloconfig.com/#/en/design/apollo-design
    roots:
      - /zh
      - /en
    # whether to enable the markdown files auto update
    scheduleEnabled: false
    # the cron expression for the markdown files auto update
    scheduleCron: 0 0 * * * ? # every hour
  processor:
    # the retry configuration when accessing openai failed
    retry:
      delay: 10000
      multiplier: 1.5
      maxDelay: 120000
      maxElapsedTime: 600000